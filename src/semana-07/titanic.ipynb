{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a95e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "feature_names = ['pclass', 'female', 'age', 'fare']\n",
    "titanic['female'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "titanic.dropna(subset=feature_names, inplace=True)  #891 para 714\n",
    "\n",
    "X = titanic[feature_names].to_numpy()\n",
    "y = titanic['survived'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tamanho de X_train: ', X_train.shape)\n",
    "print('Tamanho de X_test: ', X_test.shape)\n",
    "print('Tamanho de y_train: ', y_train.shape)\n",
    "print('Tamanho de y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca0d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ClassBin(nn.Module):\n",
    "    # Construtor\n",
    "    def __init__(self):\n",
    "        super(ClassBin, self).__init__()\n",
    "        self.linear1 = nn.Linear(4, 4)    # primeira hidden layer\n",
    "        self.dropout1 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.linear2 = nn.Linear(4, 4)    # segunda hidden layer\n",
    "        self.dropout2 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.linear3 = nn.Linear(4, 1)    # terceira hidden layer\n",
    "        self.dropout3 = nn.Dropout(0.2)   # dropout layer\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Propagação (Feed Forward)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = ClassBin()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======== ClassBin modificada ======== #\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# class ClassBin(nn.Module):\n",
    "#     # Construtor\n",
    "#     def __init__(self):\n",
    "#         super(ClassBin, self).__init__()\n",
    "#         self.linear1 = nn.Linear(4, 16)    # primeira hidden layer\n",
    "#         self.linear2 = nn.Linear(16, 8)    # segunda hidden layer\n",
    "#         self.linear3 = nn.Linear(8, 1)    # terceira hidden layer --> Camada de saída\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     # Propagação (Feed Forward)\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.linear1(x))\n",
    "#         x = F.relu(self.linear2(x))\n",
    "#         x = F.relu(self.linear3(x))\n",
    "#         x = self.sigmoid(x)\n",
    "#         return x\n",
    "\n",
    "# model = ClassBin()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a87bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "epochs = 100\n",
    "batch_size = 32  # X_train 535 / 32 = 16.71 (então são 17 batches de 32)\n",
    "#batch_size = 512  # X_train 535 / 512 = 1.05 (então são 2 batches de 512)\n",
    "#batch_size = 4  # X_train 535 / 4 = 133.75 (então são 134 batches de 4)\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instânciar o Otimizador Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05108ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ======== Usando otimizador SGD ======== #\n",
    "\n",
    "# loss_fn = nn.BCELoss()\n",
    "# epochs = 100\n",
    "# batch_size = 32  # X_train 535 / 32 = 16.71 (então são 17 batches de 32)\n",
    "# learning_rate = 0.1\n",
    "\n",
    "# # Instânciar o Otimizador SGD\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b41cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Converter X e y para torch.Tensor\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.Tensor(y_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "# Um Dataset de Tensores - Array [X, y]\n",
    "train = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1267fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    model.train() # Colocar o modelo em modo de treinamento (calcula os gradientes)\n",
    "    \n",
    "    # Batch Size\n",
    "    for data in train_loader:\n",
    "        # dar nome aos bois\n",
    "        X = data[0]\n",
    "        y = data[1]\n",
    "        \n",
    "        # Propagação (Feed Forward)\n",
    "        y_pred = model(X)\n",
    "    \n",
    "        # Calcular erro usando a função-custo\n",
    "        # y precisa virar um Tensor com tamanho (batch_size, 1)\n",
    "        loss = loss_fn(y_pred, y.unsqueeze_(1))\n",
    "        \n",
    "        # Zera os gradientes antes da Retro-propagação (Backpropagation)\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Retro-propagação (Backpropagation)\n",
    "        loss.backward()\n",
    "\n",
    "        # Atualização dos parâmetros\n",
    "        optimizer.step()\n",
    "\n",
    "    # Fim da Época\n",
    "    print(f\"\"\"Época {t + 1},\n",
    "          Custo Treino: {round(loss.item(), 3)}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # coloca o modelo em modo de avaliação (sem calcular gradientes)\n",
    "\n",
    "train_pred = model(X_train)\n",
    "train_pred = train_pred.detach().apply_(lambda x : 1 if x > 0.5 else 0)\n",
    "train_acc = torch.sum(train_pred.flatten() == y_train) / train_pred.size(0)\n",
    "\n",
    "test_pred = model(X_test)\n",
    "test_pred = test_pred.detach().apply_(lambda x : 1 if x > 0.5 else 0)\n",
    "test_acc = torch.sum(test_pred.flatten() == y_test) / test_pred.size(0)\n",
    "\n",
    "print(f\"Acurácia de Treino: {train_acc}\")\n",
    "print('\\n ---------------------------\\n')\n",
    "print(f\"Acurácia de Teste: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
